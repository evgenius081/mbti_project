{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (MBTI) Myers-Briggs Personality Type Prediction\n",
    "\n",
    "* Extroversion vs. Introversion\n",
    "    * I - 0\n",
    "    * E - 1 \n",
    "    \n",
    "* Sensing vs. Intuition \n",
    "    * N - 0 \n",
    "    * S - 1\n",
    "    \n",
    "* Thinking vs. Feeling\n",
    "    * F - 0\n",
    "    * T - 1\n",
    "    \n",
    "* Judging vs. Perceiving\n",
    "    * P - 0\n",
    "    * J - 1 \n",
    "    \n",
    "## MACHINE LEARNING - IMPLEMENTING & COMPARING DIFFERENT CLASSIFIERS  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data stratifying and splitting\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# class imbalance\n",
    "from imblearn.pipeline import make_pipeline as imb_make_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# algorithms/models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model evaluation\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# performance check\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# sparse to dense\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "\n",
    "# saving the model\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the final dataset\n",
    "path_to_csv = os.path.join(\"data\", \"clean_data_3.csv\")\n",
    "personality_data = pd.read_csv(path_to_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>is_Extrovert</th>\n",
       "      <th>is_Sensing</th>\n",
       "      <th>is_Thinking</th>\n",
       "      <th>is_Judging</th>\n",
       "      <th>posts</th>\n",
       "      <th>clean_posts</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>em</th>\n",
       "      <th>colons</th>\n",
       "      <th>emojis</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>post_length_var</th>\n",
       "      <th>upper</th>\n",
       "      <th>link_count</th>\n",
       "      <th>ellipses</th>\n",
       "      <th>img_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>'When asked of the things you wish you did ear...</td>\n",
       "      <td>asked thing wish earlier       find answering...</td>\n",
       "      <td>0.99980</td>\n",
       "      <td>0.418667</td>\n",
       "      <td>0.136150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.08</td>\n",
       "      <td>30.98</td>\n",
       "      <td>14.92</td>\n",
       "      <td>78.414931</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>'I love both and they are equally important to...</td>\n",
       "      <td>love equally important  music window soul  in...</td>\n",
       "      <td>0.99995</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.134585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.58</td>\n",
       "      <td>12.72</td>\n",
       "      <td>160.744400</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  is_Extrovert  is_Sensing  is_Thinking  is_Judging  \\\n",
       "0  INFJ             0           0            0           1   \n",
       "1  INFJ             0           0            0           1   \n",
       "\n",
       "                                               posts  \\\n",
       "0  'When asked of the things you wish you did ear...   \n",
       "1  'I love both and they are equally important to...   \n",
       "\n",
       "                                         clean_posts  compound_sentiment  \\\n",
       "0   asked thing wish earlier       find answering...             0.99980   \n",
       "1   love equally important  music window soul  in...             0.99995   \n",
       "\n",
       "   pos_sentiment  neg_sentiment  ...    em colons emojis  word_count  \\\n",
       "0       0.418667       0.136150  ...  0.22   0.32   0.08       30.98   \n",
       "1       0.600000       0.134585  ...  0.36   0.14   0.00       28.58   \n",
       "\n",
       "   unique_words  post_length_var  upper  link_count  ellipses  img_count  \n",
       "0         14.92        78.414931   1.46        0.04      0.62        0.0  \n",
       "1         12.72       160.744400   1.62        0.02      0.04        0.0  \n",
       "\n",
       "[2 rows x 126 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking top records\n",
    "personality_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting predictors and target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8588, 22)\n",
      "(8588, 4)\n"
     ]
    }
   ],
   "source": [
    "# setting X to clean_posts, compound sentiment score, pos tags and various other counts\n",
    "X = personality_data[\n",
    "    [\n",
    "        \"clean_posts\",\n",
    "        \"compound_sentiment\",\n",
    "        \"ADJ_avg\",\n",
    "        \"ADP_avg\",\n",
    "        \"ADV_avg\",\n",
    "        \"CONJ_avg\",\n",
    "        \"DET_avg\",\n",
    "        \"NOUN_avg\",\n",
    "        \"NUM_avg\",\n",
    "        \"PRT_avg\",\n",
    "        \"PRON_avg\",\n",
    "        \"VERB_avg\",\n",
    "        \"qm\",\n",
    "        \"em\",\n",
    "        \"colons\",\n",
    "        \"emojis\",\n",
    "        \"word_count\",\n",
    "        \"unique_words\",\n",
    "        \"upper\",\n",
    "        \"link_count\",\n",
    "        \"ellipses\",\n",
    "        \"img_count\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# setting y to four target classes -> is_Extrovert, is_Sensing, is_Thinking, is_Judging\n",
    "y = personality_data.iloc[:, 1:5]\n",
    "\n",
    "# ensuring that X and y row count matches\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a list of words (other than the stop words) to be dropped to improve model performanace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_stopwords = [\n",
    "    \"hey\",\n",
    "    \"hello\",\n",
    "    \"briggs\",\n",
    "    \"cat\",\n",
    "    \"car\",\n",
    "    \"mbti\",\n",
    "    \"soup\",\n",
    "    \"tea\",\n",
    "    \"sport\",\n",
    "    \"snow\",\n",
    "    \"christmas\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up preprocessor for vectorization and selecting best counts and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing steps for selecting best k columns/features from counts & scores and for vectorizing words\n",
    "\n",
    "counts_n_scores = [\n",
    "    \"compound_sentiment\",\n",
    "    \"ADJ_avg\",\n",
    "    \"ADP_avg\",\n",
    "    \"ADV_avg\",\n",
    "    \"CONJ_avg\",\n",
    "    \"DET_avg\",\n",
    "    \"NOUN_avg\",\n",
    "    \"NUM_avg\",\n",
    "    \"PRT_avg\",\n",
    "    \"PRON_avg\",\n",
    "    \"VERB_avg\",\n",
    "    \"qm\",\n",
    "    \"em\",\n",
    "    \"colons\",\n",
    "    \"emojis\",\n",
    "    \"word_count\",\n",
    "    \"unique_words\",\n",
    "    \"upper\",\n",
    "    \"link_count\",\n",
    "    \"ellipses\",\n",
    "    \"img_count\",\n",
    "]\n",
    "\n",
    "# for selecting k best features from features other than words\n",
    "best_k_features = make_pipeline(MinMaxScaler(), SelectKBest(f_classif, k=10))\n",
    "\n",
    "# setting up preprocessing for TF-IDF vectorizer\n",
    "preprocesser_tf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"tfidf\",\n",
    "            TfidfVectorizer(min_df=25, max_df=0.85, stop_words=additional_stopwords),\n",
    "            \"clean_posts\",\n",
    "        ),\n",
    "        (\"selectbest\", best_k_features, counts_n_scores),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "# setting up preprocessing for COUNT vectorizer\n",
    "preprocesser_ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"ct_vect\",\n",
    "            CountVectorizer(min_df=25, max_df=0.85, stop_words=additional_stopwords),\n",
    "            \"clean_posts\",\n",
    "        ),\n",
    "        (\"selectbest\", best_k_features, counts_n_scores),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the personality dictionary for printing scores for each class\n",
    "mbti_type = {\n",
    "    \"is_Extrovert\": \"Extrovert vs Introvert\",\n",
    "    \"is_Sensing\": \"Sensing vs Intuition\",\n",
    "    \"is_Thinking\": \"Thinking vs Feeling\",\n",
    "    \"is_Judging\": \"Judging vs Perceiving\",\n",
    "}\n",
    "\n",
    "# function to build the model for predicting each of the 4 target classes\n",
    "def build_model(model, X, target, vectorizer_name):\n",
    "\n",
    "    for col in target.columns:\n",
    "\n",
    "        print(f\"\\n{mbti_type[col]}\")\n",
    "        target = y[col]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, target, test_size=0.2, random_state=42, stratify=target\n",
    "        )\n",
    "\n",
    "        # model training\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # y_hat\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # y_probability\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # precision recall score\n",
    "        average_precision = average_precision_score(y_test, y_proba)\n",
    "\n",
    "        # model evaluation\n",
    "        print(\n",
    "            f\"Geometric Mean Score: {geometric_mean_score(y_test, y_pred, average='weighted'):.2f}\"\n",
    "        )\n",
    "        print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_proba):.2f}\")\n",
    "        print(f\"Average Precision-Recall Score: {average_precision:.2f}\")\n",
    "        print(classification_report_imbalanced(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extrovert vs Introvert\n",
      "Geometric Mean Score: 0.66\n",
      "ROC-AUC Score: 0.74\n",
      "Average Precision-Recall Score: 0.45\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.86      0.68      0.65      0.76      0.66      0.44      1322\n",
      "          1       0.37      0.65      0.68      0.47      0.66      0.44       396\n",
      "\n",
      "avg / total       0.75      0.67      0.65      0.69      0.66      0.44      1718\n",
      "\n",
      "\n",
      "Sensing vs Intuition\n",
      "Geometric Mean Score: 0.72\n",
      "ROC-AUC Score: 0.80\n",
      "Average Precision-Recall Score: 0.39\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.95      0.68      0.76      0.79      0.72      0.52      1481\n",
      "          1       0.28      0.76      0.68      0.41      0.72      0.52       237\n",
      "\n",
      "avg / total       0.85      0.69      0.75      0.74      0.72      0.52      1718\n",
      "\n",
      "\n",
      "Thinking vs Feeling\n",
      "Geometric Mean Score: 0.79\n",
      "ROC-AUC Score: 0.87\n",
      "Average Precision-Recall Score: 0.84\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.82      0.79      0.80      0.80      0.79      0.63       929\n",
      "          1       0.76      0.80      0.79      0.78      0.79      0.63       789\n",
      "\n",
      "avg / total       0.79      0.79      0.79      0.79      0.79      0.63      1718\n",
      "\n",
      "\n",
      "Judging vs Perceiving\n",
      "Geometric Mean Score: 0.63\n",
      "ROC-AUC Score: 0.68\n",
      "Average Precision-Recall Score: 0.54\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.72      0.63      0.63      0.67      0.63      0.40      1038\n",
      "          1       0.53      0.63      0.63      0.58      0.63      0.40       680\n",
      "\n",
      "avg / total       0.65      0.63      0.63      0.64      0.63      0.40      1718\n",
      "\n",
      "CPU times: user 41.1 s, sys: 1.01 s, total: 42.2 s\n",
      "Wall time: 42.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_logistic_regression = imb_make_pipeline(\n",
    "    preprocesser_tf, RandomUnderSampler(), LogisticRegressionCV()\n",
    ")\n",
    "build_model(tfidf_logistic_regression, X, y, \"tfidf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extrovert vs Introvert\n",
      "Geometric Mean Score: 0.64\n",
      "ROC-AUC Score: 0.71\n",
      "Average Precision-Recall Score: 0.40\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.86      0.66      0.63      0.74      0.64      0.42      1322\n",
      "          1       0.36      0.63      0.66      0.45      0.64      0.41       396\n",
      "\n",
      "avg / total       0.74      0.65      0.64      0.68      0.64      0.42      1718\n",
      "\n",
      "\n",
      "Sensing vs Intuition\n",
      "Geometric Mean Score: 0.68\n",
      "ROC-AUC Score: 0.75\n",
      "Average Precision-Recall Score: 0.35\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.93      0.67      0.70      0.78      0.68      0.46      1481\n",
      "          1       0.25      0.70      0.67      0.37      0.68      0.47       237\n",
      "\n",
      "avg / total       0.84      0.67      0.69      0.72      0.68      0.46      1718\n",
      "\n",
      "\n",
      "Thinking vs Feeling\n",
      "Geometric Mean Score: 0.78\n",
      "ROC-AUC Score: 0.86\n",
      "Average Precision-Recall Score: 0.82\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.81      0.77      0.79      0.79      0.78      0.61       929\n",
      "          1       0.75      0.79      0.77      0.77      0.78      0.61       789\n",
      "\n",
      "avg / total       0.78      0.78      0.78      0.78      0.78      0.61      1718\n",
      "\n",
      "\n",
      "Judging vs Perceiving\n",
      "Geometric Mean Score: 0.61\n",
      "ROC-AUC Score: 0.66\n",
      "Average Precision-Recall Score: 0.53\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.71      0.62      0.61      0.66      0.61      0.38      1038\n",
      "          1       0.51      0.61      0.62      0.56      0.61      0.38       680\n",
      "\n",
      "avg / total       0.63      0.61      0.61      0.62      0.61      0.38      1718\n",
      "\n",
      "CPU times: user 51.9 s, sys: 968 ms, total: 52.8 s\n",
      "Wall time: 53.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ct_logistic_regression = imb_make_pipeline(\n",
    "    preprocesser_ct, RandomUnderSampler(), LogisticRegressionCV()\n",
    ")\n",
    "build_model(ct_logistic_regression, X, y, \"ct_vect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Logistic Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extrovert vs Introvert\n",
      "Geometric Mean Score: 0.64\n",
      "ROC-AUC Score: 0.72\n",
      "Average Precision-Recall Score: 0.44\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.85      0.66      0.62      0.75      0.64      0.41      1322\n",
      "          1       0.36      0.62      0.66      0.45      0.64      0.41       396\n",
      "\n",
      "avg / total       0.74      0.65      0.63      0.68      0.64      0.41      1718\n",
      "\n",
      "\n",
      "Sensing vs Intuition\n",
      "Geometric Mean Score: 0.68\n",
      "ROC-AUC Score: 0.74\n",
      "Average Precision-Recall Score: 0.32\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.93      0.66      0.70      0.77      0.68      0.46      1481\n",
      "          1       0.25      0.70      0.66      0.37      0.68      0.46       237\n",
      "\n",
      "avg / total       0.84      0.67      0.69      0.72      0.68      0.46      1718\n",
      "\n",
      "\n",
      "Thinking vs Feeling\n",
      "Geometric Mean Score: 0.77\n",
      "ROC-AUC Score: 0.85\n",
      "Average Precision-Recall Score: 0.82\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.80      0.76      0.77      0.78      0.77      0.59       929\n",
      "          1       0.73      0.77      0.76      0.75      0.77      0.59       789\n",
      "\n",
      "avg / total       0.77      0.77      0.77      0.77      0.77      0.59      1718\n",
      "\n",
      "\n",
      "Judging vs Perceiving\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_logistic_regression_lasso = imb_make_pipeline(\n",
    "    preprocesser_tf, RandomUnderSampler(), LogisticRegressionCV(penalty='l1', solver='saga' )\n",
    ")\n",
    "build_model(tfidf_logistic_regression_lasso, X, y, \"tfidf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorized Logistic Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ct_logistic_regression_lasso = imb_make_pipeline(\n",
    "    preprocesser_ct, RandomUnderSampler(), LogisticRegressionCV(penalty='l1', solver='saga' )\n",
    ")\n",
    "build_model(ct_logistic_regression_lasso, X, y, \"ct_vect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Logistic Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tfidf_logistic_regression_ridge = imb_make_pipeline(\n",
    "    preprocesser_tf, RandomUnderSampler(), LogisticRegressionCV(penalty='l2', solver='saga' )\n",
    ")\n",
    "build_model(tfidf_logistic_regression_ridge, X, y, \"tfidf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorized Logistic Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ct_logistic_regression_ridge = imb_make_pipeline(\n",
    "    preprocesser_ct, RandomUnderSampler(), LogisticRegressionCV(penalty='l2', solver='saga' )\n",
    ")\n",
    "build_model(ct_logistic_regression_ridge, X, y, \"ct_vect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Logistic Elasticnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Takes longest to run and the results are almost same as lasso and ridge model. So this code is commented to save time when re-running the entire notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# for col in y.columns:\n",
    "\n",
    "#     print(f\"\\n{mbti_type[col]}\")\n",
    "\n",
    "#     target = y[col]\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, target, test_size=0.2, random_state=42, stratify=target\n",
    "#     )\n",
    "\n",
    "#     tfidf_logistic_regression_elasticnet = imb_make_pipeline(\n",
    "#         preprocesser_tf,\n",
    "#     #     DenseTransformer(),\n",
    "#         RandomUnderSampler(),\n",
    "#         LogisticRegressionCV(\n",
    "#             penalty='elasticnet',\n",
    "#             l1_ratios=[0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1],\n",
    "#             solver='saga'\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     tfidf_logistic_regression_elasticnet.fit(X_train, y_train)\n",
    "\n",
    "#     print(f'Accuracy: {tfidf_logistic_regression_elasticnet.score(X_test, y_test)} \\n')\n",
    "#     print(classification_report(y_test, tfidf_logistic_regression_elasticnet.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tfidf_svc = imb_make_pipeline(\n",
    "    preprocesser_tf, RandomUnderSampler(), DenseTransformer(), SVC(kernel='linear',probability=True)\n",
    ")\n",
    "build_model(tfidf_svc, X, y, \"tfidf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorized Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ct_svc = imb_make_pipeline(\n",
    "    preprocesser_ct, DenseTransformer(), RandomUnderSampler(), SVC(kernel='linear',probability=True)\n",
    ")\n",
    "build_model(ct_svc, X, y, \"ct_vect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tfidf_nb = imb_make_pipeline(\n",
    "    preprocesser_tf, DenseTransformer(), RandomUnderSampler(), MultinomialNB(),\n",
    ")\n",
    "build_model(tfidf_nb, X, y, \"tfidf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorized Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ct_nb = imb_make_pipeline(\n",
    "    preprocesser_ct, DenseTransformer(), RandomUnderSampler(), MultinomialNB(),\n",
    ")\n",
    "build_model(ct_nb, X, y, \"ct_vect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tfidf_rf = imb_make_pipeline(\n",
    "    preprocesser_tf, DenseTransformer(),\n",
    "        RandomUnderSampler(),\n",
    "        RandomForestClassifier(n_estimators=100, max_depth=10),\n",
    ")\n",
    "build_model(tfidf_rf, X, y, \"tfidf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorized Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ct_rf = imb_make_pipeline(\n",
    "    preprocesser_ct, RandomUnderSampler(), RandomForestClassifier(n_estimators=100, max_depth=10),\n",
    ")\n",
    "build_model(ct_rf, X, y, \"ct_vect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model - Logistic Regression with TF-IDF Vectorization\n",
    "\n",
    "Selecting TF-IDF Logistic Regression as our final model as it returned the highest scores for all metrics - accuracy, precision, recall, roc-auc, avg_precision_recall as compared to other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for col in y.columns:\n",
    "    \n",
    "    print(f\"\\n{mbti_type[col]}\")\n",
    "\n",
    "    target = y[col]\n",
    "\n",
    "    tfidf_logistic_regression = imb_make_pipeline(\n",
    "        preprocesser_tf,\n",
    "        RandomUnderSampler(),\n",
    "        LogisticRegressionCV()\n",
    "    )\n",
    "    \n",
    "    # training the data on entire dataset\n",
    "    tfidf_logistic_regression.fit(X, target)\n",
    "    \n",
    "    # feature importance   \n",
    "    coef = tfidf_logistic_regression[-1].coef_[0]  \n",
    "    word = tfidf_logistic_regression[0].named_transformers_[\"tfidf\"].get_feature_names()\n",
    "    word_list = list(zip(word, coef))         \n",
    "    result = pd.DataFrame(word_list, columns=[\"word\", \"coef\"]).set_index(\"word\")    \n",
    "    result = result.reindex(result.coef.abs().sort_values(ascending=False).index)[0:21]\n",
    "    print(result)\n",
    "    \n",
    "    # plotting feature importance\n",
    "    result[\"coef\"] = result[\"coef\"].apply(lambda x: abs(x))\n",
    "    result.sort_values(\"coef\", inplace=True)\n",
    "    result.plot(kind=\"barh\", color=\"#61BED6\", title=mbti_type[col])\n",
    "  \n",
    "    # saving the model\n",
    "    dump(tfidf_logistic_regression, f\"clf_{col}.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
